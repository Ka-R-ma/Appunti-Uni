\documentclass{subfiles}
\begin{document}
Quando si deve addestrare un modello di machine learning, ciò può essere effettuato secondo due ``logiche''., quali:
\begin{itemize}
    \item \emph{apprendimento supervisionato}: al modello sono forniti dati di addestramento in cui compaiono delle etichette\footnotemark[1];
    \item \emph{apprendimento non-supervisionato}: i dati di addestramento sono, per la maggior parte di etichette.
\end{itemize}

Indipendentemente dal modello di addestramento scelto si deve fare attenzione a due problemi: \emph{over-fitting \emph{e} under-fitting}.
Quest'ultimi fanno riferimento, rispettivamente, al caso in cui il modello, apprendendo troppo dai dati di addestramento,
non è capace di generalizzare; e al caso in cui, viceversa, non avendo appreso a sufficienza, il modello non ha le capacità minime a generalizzare.

\subsection{Apprendimento non-supervisionato}
\subfile{../Livello II/Sottosezione 3.1 - Apprendimento non supervisionato.tex}

\subsection{Apprendimento supervisionato}
\subfile{../Livello II/Sottosezione 3.2 - Apprendimento supervisionato.tex}
\footnotetext[1]{Si pensi a queste come a dei campi che definiscono la classe di appartenenza del singolo record.}
\footnotetext[2]{Si tratta di una teoria secondo la quale tutti i dati possono essere visti come appartenenti ad una qualche distribuzione ignota,
    da cui si può assumere anche la loro indipendenza. Sulla base di tale ipotesi si può allora assumere che il valore atteso dei dati di addestramento e quello dei dati di test,
    coincidano.}
\clearpage
\end{document}