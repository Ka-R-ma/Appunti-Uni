\documentclass{subfiles}
\begin{document}
Ogni progetto di scienza dei dati segue una pipeline ben definita.
Questa parte dall'ottenimento dei dati, dati che possono essere acquisiti da sorgenti diverse: sensori, file di log, ecc.
Indipendentemente dall'origine, ai dati sono legati due problematiche, quali
\begin{itemize}
    \item gestione dei dati strutturati;
    \item gestione del volume dei dati.
\end{itemize}
Assunto di aver gestito queste problematiche, si può procedere alle fasi di data-cleaning e di estrazione delle feature.
Qui con \emph{data-cleaning} si fa riferimento ad un insieme di tecniche atte a migliorare la qualità dei dati; in tale fase
\begin{itemize}
    \item si gestiscono i valori nulli: questi se non gestiti porterebbero a un cattivo addestramento del modello;
    \item si eliminano eventuali duplicati: ciò è atto a prevenire un bias nel modello;
    \item si ricercano e rimuovono eventuali outliers: è ovvio che se non si procedesse a gestirli questi influenzerebbero negativamente il modello;
    \item si standardizzano i dati: se si utilizzano dati provenienti da fonti diverse, è necessario che questi abbiano una stessa struttura.
\end{itemize}
Successivamente si può procedere alla fase di \emph{feature-extraction}: ossia la fase in cui si selezionano quelle caratteristiche valorizzabili dei dati,
che possono essere utilizzate per addestrare il modello, ed eventualmente combinate per definire concetti più generali.

\subsection{Data Integration}
\subfile{../Livello II/Sottosezione 1.1 - Integrazione dei dati.tex}

\subsection{Data integration}
\subfile{../Livello II/Sottosezione 1.2 - Trasformazione dei dati.tex}

\subsection{Data reduction}
\subfile{../Livello II/Sottosezione 1.3 - Riduzione dei dati.tex}

\subsection{Tipologie di dati}
\subfile{../Livello II/Sottosezione 1.4 - Tipologie di dati.tex}
\end{document}